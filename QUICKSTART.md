# ğŸš€ Quick Start Guide - AceBuddy RAG Chatbot

Get your high-level RAG chatbot running in 15 minutes!

## âš¡ Prerequisites

- Python 3.8+ installed
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- 93 PDF files in `data/SOP and KB Docs/` (already present)

## ğŸ“ Step-by-Step Setup

### Step 1: Install Dependencies (2 minutes)

```bash
# Install required packages
pip install -r requirements.txt
```

Expected output: ~20 packages installed

### Step 2: Configure Environment (1 minute)

```bash
# Copy environment template
copy .env.example .env

# Edit .env file and add your OpenAI API key
notepad .env
```

**Required**: Set `OPENAI_API_KEY=sk-your-key-here`

### Step 3: Process Data (10 minutes)

```bash
# Run complete data pipeline
python run_pipeline.py
```

This will:
1. âœ… Extract text from 93 PDFs
2. âœ… Clean and normalize content
3. âœ… Create semantic chunks
4. âœ… Generate embeddings
5. âœ… Build vector database

**Expected output**:
```
[STEP 1/3] Processing PDF documents...
âœ… Processed 93 documents

[STEP 2/3] Creating semantic chunks...
âœ… Created 1247 chunks

[STEP 3/3] Building vector database...
âœ… Vector database ready
```

### Step 4: Test Chatbot (2 minutes)

```bash
# Interactive testing
python test_chatbot.py
```

Try these queries:
- "I forgot my password"
- "QuickBooks error -6177"
- "Can't connect to RDP"

Or run automated tests:
```bash
python test_chatbot.py auto
```

### Step 5: Start API Server (1 minute)

```bash
# Start FastAPI server
python src/api.py
```

Server runs at: http://localhost:8000

Test it:
```bash
# Health check
curl http://localhost:8000/health

# Chat request
curl -X POST http://localhost:8000/chat ^
  -H "Content-Type: application/json" ^
  -d "{\"query\": \"I forgot my password\"}"
```

## âœ… Verification

Your chatbot is ready if:
- âœ… Pipeline completed without errors
- âœ… Test queries return relevant responses
- âœ… API server responds to health check
- âœ… Chat endpoint returns answers

## ğŸ¯ Next Steps

### Option A: Continue Testing
```bash
# Test more queries
python test_chatbot.py

# Check API documentation
# Open browser: http://localhost:8000/docs
```

### Option B: Deploy to Production
See `IMPLEMENTATION_PLAN.md` Phase 4 for:
- Cloud deployment
- Zoho SalesIQ integration
- Webhook configuration

### Option C: Customize
Edit these files:
- `config.py` - Adjust RAG parameters
- `src/rag_engine.py` - Modify system prompt
- `src/chunker.py` - Change chunk size

## ğŸ› Troubleshooting

### Error: "No module named 'openai'"
```bash
pip install -r requirements.txt
```

### Error: "OPENAI_API_KEY not found"
```bash
# Make sure .env file exists and contains:
OPENAI_API_KEY=sk-your-actual-key
```

### Error: "No PDFs found"
```bash
# Verify PDFs exist
dir "data\SOP and KB Docs"
# Should show 93 PDF files
```

### Error: "ChromaDB error"
```bash
# Clear and rebuild
rmdir /s /q data\chroma
python run_pipeline.py
```

### Slow processing
- Normal: 10-20 minutes for first run
- Embeddings generation takes time
- Subsequent runs are faster (cached)

## ğŸ“Š What You Built

- **Knowledge Base**: 93 PDFs + 10 KB articles
- **Chunks**: ~1200-1500 semantic chunks
- **Vector DB**: ChromaDB with OpenAI embeddings
- **API**: FastAPI with 6 endpoints
- **RAG Engine**: Context-aware response generation

## ğŸ’° Costs

- **Setup**: ~$0.50 (one-time embeddings)
- **Monthly**: ~$20-30 (800 queries)
- **ROI**: Save ~$1,700/month in support costs

## ğŸ‰ Success!

You now have a production-ready RAG chatbot that can:
- Answer 40-60% of support queries automatically
- Provide accurate, context-aware responses
- Escalate complex queries to human agents
- Integrate with Zoho SalesIQ via webhook

## ğŸ“š Learn More

- `README.md` - Full documentation
- `IMPLEMENTATION_PLAN.md` - Detailed implementation guide
- `PROJECT_STRUCTURE.md` - Code organization
- API Docs: http://localhost:8000/docs

## ğŸ¤ Need Help?

Common issues:
1. **API key issues**: Check `.env` file
2. **Import errors**: Run `pip install -r requirements.txt`
3. **PDF errors**: Some PDFs may fail (normal, others will work)
4. **Slow responses**: First query is slower (model loading)

Ready to revolutionize your support! ğŸš€
